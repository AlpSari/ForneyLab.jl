{
 "metadata": {
  "language": "Julia",
  "name": "variational_message_passing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Variational message passing demo\n===\n\nThe variational method is used to approximate an intractable posterior distribution when hidden variables are present. Variational approximation can be viewed as the minimization of a variational free energy function. This free energy measures the dissimilarity between the intractable true posterior and a more friendly approximate distribution. When the Kullback Leibler divergence is used as dissimilariy measure, the approximate distribution lives under the true posterior and attempts to fit the local properties of the posterior distribution.\n\nVariational methods often involve complicated and extensive derivations in order to execute the free energy minimizations. Variational message passing (VMP) eases our derivation troubles by expressing them as local update rules, using the factorization of the posterior. In his 2007 article, Dauwels gives a generic introduction to VMP on a factor graph. We will implement this VMP approach for the case of a univariate Gaussian posterior. We wish to estimate the latent mean and variance of this Gaussian using VMP.\n\nThe corresponding factor graph is shown below, where $q(m)$ and $q(s)$ represent the approximated marginals for the mean and variance respectively. Variational messages $v(.)$ are passed forward and backward, and $q(.)=\\overrightarrow{v}(.) \\times \\overleftarrow{v}(.)$. We observe the samples `y` and wish to estimate the posterior distribution over the mean and variance given the samples.\n\n\n```\n [s_prior]---------->[=]---------->[=]--->    -->[C_s]\n                      |             |   etc...\n [m_prior]-->[=]---------->[=]--------->      -->[C_m]\n          q(m)|   q(s)|     |       |\n              -->[N]<--     -->[N]<--\n                  |             |\n                  v y_1         v y_2\n```\n\nWe start by building this graph."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "using(ForneyLab)\n\n# Initial settings\nn_samples = 10 # Number of observed samples\nn_its = 10 # Number of vmp iterations\ntrue_mean = 5.0\ntrue_variance = 2.0\ny_observations = sqrt(true_variance)*randn(n_samples)+true_mean # y observation buffer\n\n# Pre-assign arrays for later reference\ng_nodes = Array(GaussianNode, n_samples)\nm_eq_nodes = Array(EqualityNode, n_samples)\ns_eq_nodes = Array(EqualityNode, n_samples)\nobs_nodes = Array(ConstantNode, n_samples)\nq_s_edges = Array(Edge, n_samples)\nq_m_edges = Array(Edge, n_samples)\ny_edges = Array(Edge, n_samples)\n\n# Build graph\nfor section=1:n_samples\n    g_node = GaussianNode(true) # Variational flag set to true, so updateNodeMessage knows what formula to use\n    m_eq_node = EqualityNode() # Equality node chain for mean\n    s_eq_node = EqualityNode() # Equality node chain for variance\n    obs_node = ConstantNode(GeneralMessage(y_observations[section])) # Observed y values are stored as constant node values\n    g_nodes[section] = g_node\n    m_eq_nodes[section] = m_eq_node\n    s_eq_nodes[section] = s_eq_node\n    obs_nodes[section] = obs_node\n    y_edges[section] = Edge(g_node.out, obs_node.out)\n    q_m_edges[section] = Edge(m_eq_node.interfaces[3], g_node.in1)\n    q_s_edges[section] = Edge(s_eq_node.interfaces[3], g_node.in2)\n    setMessage!(q_s_edges[section].head, GammaMessage(a=-1.0, b=0.0, inverted=true)) # Set some neutral 'one' messages on marginal interfaces\n    setMessage!(q_s_edges[section].tail, GammaMessage(a=-1.0, b=0.0, inverted=true))\n    setMessage!(q_m_edges[section].head, GaussianMessage(m=[0.0], V=[1.0e12])) # More neutral 'one' messages\n    setMessage!(q_m_edges[section].tail, GaussianMessage(m=[0.0], V=[1.0e12]))\n    q_m_edges[section].marginal = GaussianMessage() # Predefine an arbitrary marginal to indicate these edges are variational\n    q_s_edges[section].marginal = GammaMessage()\n    if section > 1\n        Edge(m_eq_nodes[section-1].interfaces[2], m_eq_nodes[section].interfaces[1])\n        Edge(s_eq_nodes[section-1].interfaces[2], s_eq_nodes[section].interfaces[1])\n    end\nend\n# Attach beginning and end nodes\nm_prior = ConstantNode(GaussianMessage(m=[0.0], V=[100.0])) # Prior\ns_prior = ConstantNode(GammaMessage(a=0.01, b=0.01, inverted=true)) # Prior\nc_m = ConstantNode(GaussianMessage(m=[0.0], V=[1.0e12])) # Neutral 'one' message\nc_s = ConstantNode(GammaMessage(a=-1.0, b=0.0, inverted=true)) # Neutral 'one' message\nEdge(m_prior.out, m_eq_nodes[1].interfaces[1])\nEdge(s_prior.out, s_eq_nodes[1].interfaces[1])\nEdge(m_eq_nodes[end].interfaces[2], c_m.out)\nEdge(s_eq_nodes[end].interfaces[2], c_s.out);",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Next we need to specify an update schedule. This requires some insight in what messages we require to accomplish our task. Before we can recalculate a marginal we need to update both the forward and backward message of the edge. We need to build two custom schedules: one schedule to specify the order in which we want to update the standard sumproduct messages, and another to indicate the order in which we want to update the marginals."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Sumproduct updates\n# Update for mean equality chain\nleft_update_run_m = generateSchedule(m_eq_nodes[1].interfaces[1])\nright_update_run_m = generateSchedule(m_eq_nodes[end].interfaces[2])\ndownward_m = map(x -> x.interfaces[3], m_eq_nodes)\n# Update for variance equality chain\nleft_update_run_s = generateSchedule(s_eq_nodes[1].interfaces[1])\nright_update_run_s = generateSchedule(s_eq_nodes[end].interfaces[2])\ndownward_s = map(x -> x.interfaces[3], s_eq_nodes)\n# Update for samples\nupward_y = Array(Interface, 0)\nfor node = g_nodes\n    push!(upward_y, node.out.partner)\n    push!(upward_y, node.in1)\n    push!(upward_y, node.in2)\nend\n# Put it all together\nsumproduct_schedule = [left_update_run_m, right_update_run_m, downward_m, left_update_run_s, right_update_run_s, downward_s, upward_y]\n\n# Marginal updates\nmarginal_schedule = [q_m_edges, q_s_edges];",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now we can iteratively execute these schedules and inspect the results. "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Perform vmp updates\nfor iter = 1:n_its\n    executeSchedule(sumproduct_schedule)\n    executeSchedule(marginal_schedule)\nend\nexecuteSchedule(sumproduct_schedule) # One last time to ensure all calculations have propagated through the equality chains\n# Save outcome\nensureMVParametrization!(m_eq_nodes[end].interfaces[2].message)\nm = m_eq_nodes[end].interfaces[2].message.m[1]\nV = m_eq_nodes[end].interfaces[2].message.V[1, 1]\na = s_eq_nodes[end].interfaces[2].message.a\nb = s_eq_nodes[end].interfaces[2].message.b\n\n# Inspect the results\nprintln(\"True mean: $(true_mean)\")\nprintln(\"True variance: $(true_variance)\")\nprintln(\"Number of samples: $(length(y_observations))\")\nprintln(\"Sample mean: $(mean(y_observations))\")\nprintln(\"Sample variance: $(var(y_observations))\")\nprintln(\"\\n----- Estimation after $(n_its) VMP updates -----\")\nprintln(\"Mean estimate: $(m), with variance $(V)\")\nprintln(\"Variance estimate: $(b/(a-1)), with variance $(b^2/(((a-1)^2)*(a-2)))\")",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "True mean: 5.0\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "True variance: 2.0\nNumber of samples: 10\nSample mean: 5.922958564089426\nSample variance: 3.193778613095562\n\n----- Estimation after 10 VMP updates -----\nMean estimate: 5.920519404076537, with variance 0.041181446392782955\nVariance estimate: 3.637890458444688, with variance 4.396759796559104\n"
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}