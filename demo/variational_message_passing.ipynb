{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:a4bbed390f8d73e5f8895f0377e078d22a7b8f80e57c16765a5c924804d73ead"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variational message passing demo\n",
      "===\n",
      "\n",
      "The variational method is used to approximate an intractable posterior distribution when hidden variables are present. Variational approximation can be viewed as the minimization of a variational free energy function. This free energy measures the dissimilarity between the intractable true posterior and a more friendly approximate distribution. When the Kullback Leibler divergence is used as dissimilariy measure, the approximate distribution lives under the true posterior and attempts to fit the local properties of the posterior distribution.\n",
      "\n",
      "Variational methods often involve complicated and extensive derivations in order to execute the free energy minimizations. Variational message passing (VMP) eases our derivation troubles by expressing the variational algorithm in terms of local update rules, using the factorization of the posterior. In his 2007 article, Dauwels gives a generic introduction to VMP on a factor graph. We will implement this VMP approach for the case of a univariate Gaussian posterior. We wish to estimate the latent mean and variance of this Gaussian using VMP.\n",
      "\n",
      "The corresponding factor graph is shown below, where $q(m)$ and $q(s)$ represent the approximated marginals for the mean and variance respectively. Variational messages $v(.)$ are passed forward and backward, and the approximate marginals $q(.)$ are calculated as $q(.)=\\overrightarrow{v}(.) \\times \\overleftarrow{v}(.)$. We observe the samples `y` and wish to estimate the posterior distribution over the mean and variance given these samples.\n",
      "\n",
      "\n",
      "```\n",
      " [s_prior]---------->[=]---------->[=]--->    -->[C_s]\n",
      "                      |             |   etc...\n",
      " [m_prior]-->[=]---------->[=]--------->      -->[C_m]\n",
      "          q(m)|   q(s)|     |       |\n",
      "              -->[N]<--     -->[N]<--\n",
      "                  |             |\n",
      "                  v y_1         v y_2\n",
      "```\n",
      "\n",
      "We start by building this graph."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using(ForneyLab)\n",
      "\n",
      "# Initial settings\n",
      "n_samples = 10 # Number of observed samples\n",
      "n_its = 50 # Number of vmp iterations\n",
      "true_mean = 5.0\n",
      "true_variance = 2.0\n",
      "y_observations = sqrt(true_variance)*randn(n_samples)+true_mean # y observation buffer\n",
      "\n",
      "# Pre-assign arrays for later reference\n",
      "g_nodes = Array(GaussianNode, n_samples)\n",
      "m_eq_nodes = Array(EqualityNode, n_samples)\n",
      "s_eq_nodes = Array(EqualityNode, n_samples)\n",
      "obs_nodes = Array(TerminalNode, n_samples)\n",
      "q_s_edges = Array(Edge, n_samples)\n",
      "q_m_edges = Array(Edge, n_samples)\n",
      "y_edges = Array(Edge, n_samples)\n",
      "\n",
      "# Build graph\n",
      "for section=1:n_samples\n",
      "    g_node = GaussianNode()\n",
      "    m_eq_node = EqualityNode() # Equality node chain for mean\n",
      "    s_eq_node = EqualityNode() # Equality node chain for variance\n",
      "    obs_node = TerminalNode(y_observations[section]) # Observed y values are stored in terminal node values\n",
      "    g_nodes[section] = g_node\n",
      "    m_eq_nodes[section] = m_eq_node\n",
      "    s_eq_nodes[section] = s_eq_node\n",
      "    obs_nodes[section] = obs_node\n",
      "    y_edges[section] = Edge(g_node.out, obs_node.out, Float64) # Float64 implies the edge accepts numeric message payloads\n",
      "    q_m_edges[section] = Edge(m_eq_node.interfaces[3], g_node.mean)\n",
      "    q_s_edges[section] = Edge(s_eq_node.interfaces[3], g_node.variance, InverseGammaDistribution) # This edge accepts messages with an InverseGamma distribution\n",
      "    # Preset uninformative ('one') messages\n",
      "    setMarginal!(q_s_edges[section], uninformative(InverseGammaDistribution))\n",
      "    setMarginal!(q_m_edges[section], uninformative(GaussianDistribution))\n",
      "    if section > 1 # Connect sections\n",
      "        Edge(m_eq_nodes[section-1].interfaces[2], m_eq_nodes[section].interfaces[1])\n",
      "        Edge(s_eq_nodes[section-1].interfaces[2], s_eq_nodes[section].interfaces[1], InverseGammaDistribution)\n",
      "    end\n",
      "end\n",
      "# Attach beginning and end nodes\n",
      "m_prior = TerminalNode(GaussianDistribution(m=0.0, V=100.0)) # Prior\n",
      "s_prior = TerminalNode(InverseGammaDistribution(a=0.01, b=0.01)) # Prior\n",
      "c_m = TerminalNode(uninformative(GaussianDistribution)) # Neutral 'one' message\n",
      "c_s = TerminalNode(uninformative(InverseGammaDistribution)) # Neutral 'one' message\n",
      "Edge(m_prior.out, m_eq_nodes[1].interfaces[1])\n",
      "Edge(s_prior.out, s_eq_nodes[1].interfaces[1], InverseGammaDistribution)\n",
      "Edge(m_eq_nodes[end].interfaces[2], c_m.out)\n",
      "Edge(s_eq_nodes[end].interfaces[2], c_s.out, InverseGammaDistribution);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we need to specify an update schedule. This requires some insight in what messages we require to accomplish our task. Before we can recalculate a marginal we need to update both the forward and backward message of the edge. We need to build two custom schedules: one schedule to specify the order in which we want to update the standard sumproduct messages, and another to indicate the order in which we want to update the marginals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sumproduct updates\n",
      "# Update for mean equality chain\n",
      "left_update_run_m = generateSchedule(m_eq_nodes[1].interfaces[1])\n",
      "right_update_run_m = generateSchedule(m_eq_nodes[end].interfaces[2])\n",
      "downward_m = map(x -> x.interfaces[3], m_eq_nodes)\n",
      "# Update for variance equality chain\n",
      "left_update_run_s = generateSchedule(s_eq_nodes[1].interfaces[1])\n",
      "right_update_run_s = generateSchedule(s_eq_nodes[end].interfaces[2])\n",
      "downward_s = map(x -> x.interfaces[3], s_eq_nodes)\n",
      "#downward_s = [x.interfaces[3] for x in s_eq_nodes]\n",
      "# Update for samples\n",
      "upward_y = Array(Interface, 0)\n",
      "for node = g_nodes\n",
      "    push!(upward_y, node.out.partner)\n",
      "    push!(upward_y, node.mean)\n",
      "    push!(upward_y, node.variance)\n",
      "end\n",
      "# Put it all together\n",
      "sumproduct_schedule = [left_update_run_m, right_update_run_m, downward_m, left_update_run_s, right_update_run_s, downward_s, upward_y]\n",
      "\n",
      "# Marginal updates\n",
      "marginal_schedule = [q_m_edges, q_s_edges];"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can iteratively execute these schedules and inspect the results. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Perform vmp updates\n",
      "for iter = 1:n_its\n",
      "    executeSchedule(sumproduct_schedule)\n",
      "    executeSchedule(marginal_schedule)\n",
      "end\n",
      "executeSchedule(sumproduct_schedule) # One last time to ensure all calculations have propagated through the equality chains\n",
      "\n",
      "# Save outcome\n",
      "ensureMVParametrization!(m_eq_nodes[end].interfaces[2].message.payload)\n",
      "\n",
      "# Inspect the results\n",
      "println(\"True mean: $(true_mean)\")\n",
      "println(\"True variance: $(true_variance)\")\n",
      "println(\"Number of samples: $(length(y_observations))\")\n",
      "println(\"Sample mean: $(mean(y_observations))\")\n",
      "println(\"Sample variance: $(var(y_observations))\")\n",
      "println(\"\\n----- Estimation after $(n_its) VMP updates -----\")\n",
      "println(\"Mean estimate: $(mean(m_eq_nodes[end].interfaces[2].message.payload)[1]), with variance $(var(m_eq_nodes[end].interfaces[2].message.payload)[1, 1])\")\n",
      "println(\"Variance estimate: $(mean(s_eq_nodes[end].interfaces[2].message.payload)), with variance $(var(s_eq_nodes[end].interfaces[2].message.payload))\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True mean: 5.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True variance: 2.0\n",
        "Number of samples: 10\n",
        "Sample mean: 5.080764756154494\n",
        "Sample variance: 3.4450957117936842\n",
        "\n",
        "----- Estimation after 50 VMP updates -----\n",
        "Mean estimate: 5.078820884363364, with variance 0.03825920090202556\n",
        "Variance estimate: 3.916269982969169, with variance 5.095405508141307\n"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}