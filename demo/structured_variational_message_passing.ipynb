{
 "metadata": {
  "language": "Julia",
  "name": "structured_variational_message_passing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Structured variational message passing demo\n===\n\nVMP under the mean field approximation tends to be overconfident in the precision estimation. In the structured VMP (SVMP) method, the factorization of q is less constrained. SVMP allows arbitrary factorizations of the approximating `q` distribution. The factorization defines subgraphs (regions) with internal and external edges (Dauwels 2007). Internal edges carry standard sum-product messages while external edges and their connected nodes carry (joint) marginals.\n\nAs an example case to illustrate and test our SVMP implementation in ForneyLab, we estimate the mean and variance of samples drawn from a Gaussian distribution. We factorize the approximating distribution as `q(m,gam,y)=q(m,gam)q(y)`. While the VMP approximation with the full factorization `q(m)q(gam)` lives under the true posterior, the joint `q(m,gam)` factor in SVMP will fit the true posterior better.\n\nA graph representation for multiple samples simultaneously introduces cycles in the `q(m, gam)` subgraph, which is against the assumptions for a variational algorithm. We have to resort to an online estimation, taking one sample at a time. The subgraph definitions are as follows:\n\n```\n         gam_0        gam_1       \n[T]---------------[=]------>[T] \n    m_0      m_1   |            \n[T]---->[=]--------|------->[T]      .         .\n         |         |                 .q(m, gam).\n       m --->[N]<--- gam             . .>[N]<. .\n              .                           |\n              . q(y)                      | y\n              v                           v\n                                         [T]\n```\n\nWe begin by implementing the graph in ForneyLab and defining the structured factoriation. Note that the edges for `m` and `gam` now belong to the same subgraph."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "using(ForneyLab)\n\n# Initialize nodes and edges\ng_node = GaussianNode(; name=\"g_node\", form=\"precision\")\nm_eq_node = EqualityNode(; name=\"m_eq_node\") # Equality node for mean\ngam_eq_node = EqualityNode(; name=\"gam_eq_node\") # Equality node for precision\ny_node = TerminalNode(GaussianDistribution(), name=\"y_node\") # Observed y values are stored in y_node\ny_edge = Edge(g_node.out, y_node.out, GaussianDistribution)\nm_edge = Edge(m_eq_node.interfaces[3], g_node.mean, GaussianDistribution, StudentsTDistribution)\ngam_edge = Edge(gam_eq_node.interfaces[3], g_node.precision, GammaDistribution)\n\n# Attach beginning and end nodes\nm_0_node = TerminalNode(GaussianDistribution(m=0.0, V=100.0)) # Prior\ngam_0_node = TerminalNode(GammaDistribution(a=0.01, b=0.01)) # Prior\nm_N_node = TerminalNode(uninformative(GaussianDistribution)) # Neutral 'one' message\ngam_N_node = TerminalNode(uninformative(GammaDistribution)) # Neutral 'one' message\nm_0_eq_edge = Edge(m_0_node.out, m_eq_node.interfaces[1], GaussianDistribution)\ngam_0_eq_edge = Edge(gam_0_node.out, gam_eq_node.interfaces[1], GammaDistribution)\nm_N_eq_edge = Edge(m_eq_node.interfaces[2], m_N_node.out, GaussianDistribution)\ngam_N_eq_edge = Edge(gam_eq_node.interfaces[2], gam_N_node.out, GammaDistribution);",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now we need to specify the factorization, update schedules for both subgraphs and set the uninformative marginals."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Define the structured factorization\nfactorize!(y_edge)\n\n# Update schedules for q(m, gam) subgraph\nm_gam_subgraph = getSubgraph(m_edge)\ngenerateSchedule!(m_gam_subgraph)\n# Update schedules for q(y) subgraph\ny_subgraph = getSubgraph(y_edge)\ngenerateSchedule!(y_subgraph)\n\n# Preset the uninformative marginals\nsetUninformativeMarginals!();",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Next we generate some data and specify the number of VMP iterations."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "true_mean = 5.0\ntrue_prec = 0.5\nn_samples = 100 # Draw 100 samples\ndata = randn(n_samples)*(1/sqrt(true_prec))+true_mean\nn_its = 10; # Number of VMP iterations per data point",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": "10"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now the setup is done and we can start the iterations."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "for sample = 1:n_samples\n    # Reset\n    y_node.value = GaussianDistribution(m = data[sample], W=10.0) # Sample with measurement noise\n\n    # Do the VMP iterations\n    for it = 1:n_its\n        # Update q(y)\n        executeSchedule(y_subgraph)\n        # Update q(m, gam)\n        executeSchedule(m_gam_subgraph)\n    end\n    # Make sure the messages get propagated to the right\n    executeSchedule([m_N_node.out.partner, gam_N_node.out.partner])\n\n    # Switch posterior to prior for next sample\n    m_0_node.value = deepcopy(m_N_node.out.partner.message.payload)\n    gam_0_node.value = deepcopy(gam_N_node.out.partner.message.payload)\nend\n\nm_out = m_N_node.out.partner.message.payload\ngam_out = gam_N_node.out.partner.message.payload;",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Let's inspect the results."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "println(\"True mean: $(true_mean)\")\nprintln(\"True precision: $(true_prec)\")\nprintln(\"Number of samples: $(n_samples)\")\nprintln(\"Sample mean: $(mean(data))\")\nprintln(\"Sample precision: $(1/var(data))\")\nprintln(\"\\n----- Online estimation after $(n_its) VMP updates per sample -----\")\nprintln(\"Mean estimate: $(mean(m_out)[1]), with variance $(var(m_out)[1])\")\nprintln(\"Precision estimate: $(mean(gam_out)), with variance $(var(gam_out))\")",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "True mean: 5.0\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "True precision: 0.5\nNumber of samples: 100\nSample mean: 4.968934451766342\nSample precision: 0.529777426931435\n\n----- Online estimation after 10 VMP updates per sample -----\nMean estimate: 4.874778795918297, with variance 0.023364715484866103\nPrecision estimate: 0.5136606232001484, with variance 0.0052758895386195714"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n"
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}