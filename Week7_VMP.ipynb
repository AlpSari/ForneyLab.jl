{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling ForneyLab [9fc3f58a-c2cc-5bff-9419-6a294fefdca9]\n",
      "└ @ Base loading.jl:1278\n",
      "WARNING: Method definition (::ForneyLab.var\"#logp_nc#360\"{msg_out, thenode, inx_list, arg_sample, j})(Any) in module ForneyLab at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:128 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:131.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{ForneyLab.DefaultOptim})() in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:257.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{ForneyLab.DefaultOptim}) in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:257.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{ForneyLab.ConvergenceStatsFE})() in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:276.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{ForneyLab.ConvergenceStatsFE}) in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:276.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{ForneyLab.ConvergenceParamsFE})() in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:289.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{ForneyLab.ConvergenceParamsFE}) in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:289.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{ForneyLab.ConvergenceParamsMC})() in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:320.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{ForneyLab.ConvergenceParamsMC}) in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:320.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition (::Type{ForneyLab.ParamStr2})() in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:362.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition Type##kw(Any, Type{ForneyLab.ParamStr2}) in module ForneyLab at util.jl:438 overwritten at C:\\AlpOkul\\TUe_Masters\\Internship_BIASLab\\CVI_AlpSemih\\src\\engines\\julia\\update_rules\\cvi.jl:362.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n"
     ]
    }
   ],
   "source": [
    "using Random,LinearAlgebra, Flux.Optimise, Plots, ForneyLab\n",
    "using ForneyLab:ParamStr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "m_data = 3.0\n",
    "w_data = 4.0\n",
    "y_data = sqrt(1/w_data)*randn(n) .+ m_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.943261165197841\n",
      "2.9422682960987996\n",
      "2.942070654327122\n",
      "2.942031313297883\n",
      "2.9420234824504488\n",
      "2.942021923719979\n",
      "2.9420216134547337\n",
      "2.9420215516964507\n",
      "2.942021539403469\n",
      "2.9420215369565508\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = FactorGraph()\n",
    "# Priors\n",
    "@RV m ~ GaussianMeanVariance(0.0, 100.0)\n",
    "@RV w ~ Gamma(0.01, 0.01)\n",
    "\n",
    "# Observarion model\n",
    "y = Vector{Variable}(undef, n)\n",
    "for i = 1:n\n",
    "    @RV y[i] ~ GaussianMeanPrecision(m, w)\n",
    "    placeholder(y[i], :y, index=i)\n",
    "end\n",
    "\n",
    "# Specify posterior factorization\n",
    "q = PosteriorFactorization(m, w, ids=[:M, :W])\n",
    "# Build the variational update algorithms for each posterior factor\n",
    "algo = messagePassingAlgorithm(free_energy=true)\n",
    "\n",
    "# Generate source code for the algorithms\n",
    "source_code = algorithmSourceCode(algo, free_energy=true)\n",
    "\n",
    "# And inspect the algorithm code\n",
    "#println(source_code)\n",
    "eval(Meta.parse(source_code));\n",
    "data = Dict(:y => y_data)\n",
    "\n",
    "# Initial posterior factors\n",
    "marginals = Dict(:m => vague(GaussianMeanVariance),\n",
    "                 :w => vague(Gamma))\n",
    "\n",
    "n_its = 2*n\n",
    "F = Vector{Float64}(undef, n_its) # Initialize vector for storing Free energy\n",
    "m_est = Vector{Float64}(undef, n_its)\n",
    "w_est = Vector{Float64}(undef, n_its)\n",
    "for i = 1:n_its\n",
    "    stepM!(data, marginals)\n",
    "    stepW!(data, marginals)\n",
    "    println(mean(marginals[:m]))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Initial Step Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Convergence Algo, Automatic Step Size, Constant Step Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inexactLineSearch failed, setting initial stepsize to 1.0e-5\n",
      "Importance ratios are 0, fitted Pareto shape parameter = NaN\n",
      "1.0\n",
      "---\n",
      "Fitted Pareto shape parameter = -0.577467919589317\n",
      "0.9999842167056614\n",
      "---\n",
      "Fitted Pareto shape parameter = -0.6158958032557569\n",
      "1.005700102491064\n",
      "---\n",
      "Fitted Pareto shape parameter = -0.6052632984298429\n",
      "1.000809722721084\n",
      "---\n",
      "Importance ratios are 0, fitted Pareto shape parameter = NaN\n",
      "0.9999999999941968\n",
      "---\n",
      "Fitted Pareto shape parameter = -0.5470372202276892\n",
      "1.0000007965060311\n",
      "---\n",
      "Importance ratios are 0, fitted Pareto shape parameter = NaN\n",
      "1.0000000000167844\n",
      "---\n",
      "Fitted Pareto shape parameter = -0.6358846794982078\n",
      "1.019523232234491\n",
      "---\n",
      "Fitted Pareto shape parameter = -0.513649776303838\n",
      "1.0000000695424829\n",
      "---\n",
      "Fitted Pareto shape parameter = -0.5635962282250015\n",
      "1.000000004512718\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "opt = ParamStr2(max_iterations=1e5,stepsize_update=\"none\",convergence_algo=\"none\",verbose=true)\n",
    "# CVI Implementation\n",
    "f(x) = x^6\n",
    "# Priors\n",
    "graph2 = FactorGraph()\n",
    "@RV m ~ GaussianMeanVariance(1.0, 100.0)\n",
    "@RV m_bar ~ Cvi(m,g=f,opt=opt,num_samples=1000,num_iterations=1)\n",
    "@RV w ~ Gamma(0.01, 0.01)\n",
    "\n",
    "# Observarion model\n",
    "y = Vector{Variable}(undef, n)\n",
    "for i = 1:n\n",
    "    @RV y[i] ~ GaussianMeanPrecision(m_bar, w)\n",
    "    placeholder(y[i], :y, index=i)\n",
    "end\n",
    "\n",
    "# Specify posterior factorization\n",
    "q = PosteriorFactorization(m, w, ids=[:M, :W])\n",
    "# Build the variational update algorithms for each posterior factor\n",
    "algo = messagePassingAlgorithm(free_energy=true)\n",
    "\n",
    "# Generate source code for the algorithms\n",
    "source_code = algorithmSourceCode(algo, free_energy=true)\n",
    "\n",
    "# And inspect the algorithm code\n",
    "#println(source_code)\n",
    "eval(Meta.parse(source_code));\n",
    "\n",
    "\n",
    "data = Dict(:y => y_data)\n",
    "\n",
    "# Initial posterior factors\n",
    "marginals2 = Dict(:m => vague(GaussianMeanVariance),\n",
    "                 :w => vague(Gamma))\n",
    "\n",
    "n_its = 2*n\n",
    "F = Vector{Float64}(undef, n_its) # Initialize vector for storing Free energy\n",
    "m_est = Vector{Float64}(undef, n_its)\n",
    "w_est = Vector{Float64}(undef, n_its)\n",
    "for i = 1:n_its\n",
    "    stepM!(data, marginals2)\n",
    "    stepW!(data, marginals2)\n",
    "    println(mean(marginals2[:m]))\n",
    "    println(\"---\")\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5275395543276837e-10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5*0.9^200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance ratios are 0, fitted Pareto shape parameter = NaN\n",
      "2.814583582072744\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =0.8306631844210011>=0.7!\n",
      "2.929148578340885\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0985896677343712>=0.7!\n",
      "2.9408421844533637\n",
      "---\n",
      "Fitted Pareto shape parameter = 0.4764553158658591\n",
      "2.8885776936645984\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0351646408116881>=0.7!\n",
      "2.9402200901841895\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =0.8629416597643405>=0.7!\n",
      "2.9321968475636013\n",
      "---\n",
      "Fitted Pareto shape parameter = 0.168020232907223\n",
      "2.88799961401796\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =0.9675459246038264>=0.7!\n",
      "2.936672125396336\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0870097113916484>=0.7!\n",
      "2.9358386334435465\n",
      "---\n",
      "Fitted Pareto shape parameter = 0.5545350759086243\n",
      "2.9009245310438727\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "opt = ParamStr2(max_iterations=1e5,stepsize_update=\"adaptive\",convergence_algo=\"none\",verbose=true)\n",
    "#opt = Descent(0.5)\n",
    "# CVI Implementation\n",
    "f(x) = x\n",
    "# Priors\n",
    "graph2 = FactorGraph()\n",
    "@RV m ~ GaussianMeanVariance(1.0, 100.0)\n",
    "@RV m_bar ~ Cvi(m,g=f,opt=opt,num_samples=1000,num_iterations=1000)\n",
    "@RV w ~ Gamma(0.01, 0.01)\n",
    "\n",
    "# Observarion model\n",
    "y = Vector{Variable}(undef, n)\n",
    "for i = 1:n\n",
    "    @RV y[i] ~ GaussianMeanPrecision(m_bar, w)\n",
    "    placeholder(y[i], :y, index=i)\n",
    "end\n",
    "\n",
    "# Specify posterior factorization\n",
    "q = PosteriorFactorization(m, w, ids=[:M, :W])\n",
    "# Build the variational update algorithms for each posterior factor\n",
    "algo = messagePassingAlgorithm(free_energy=true)\n",
    "\n",
    "# Generate source code for the algorithms\n",
    "source_code = algorithmSourceCode(algo, free_energy=true)\n",
    "\n",
    "# And inspect the algorithm code\n",
    "#println(source_code)\n",
    "eval(Meta.parse(source_code));\n",
    "\n",
    "\n",
    "data = Dict(:y => y_data)\n",
    "\n",
    "# Initial posterior factors\n",
    "marginals2 = Dict(:m => vague(GaussianMeanVariance),\n",
    "                 :w => vague(Gamma))\n",
    "\n",
    "n_its = 2*n\n",
    "F = Vector{Float64}(undef, n_its) # Initialize vector for storing Free energy\n",
    "m_est = Vector{Float64}(undef, n_its)\n",
    "w_est = Vector{Float64}(undef, n_its)\n",
    "for i = 1:n_its\n",
    "    stepM!(data, marginals2)\n",
    "    stepW!(data, marginals2)\n",
    "    println(mean(marginals2[:m]))\n",
    "    println(\"---\")\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inexactLineSearch succeeded, setting initial stepsize to 5.886836577006101e-8\n",
      "Importance ratios are 0, fitted Pareto shape parameter = NaN\n",
      "1.0131540556020504\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0431518225868692>=0.7!\n",
      "1.8334666777010793\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0905691266185282>=0.7!\n",
      "1.090252732988495\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.093801073824839>=0.7!\n",
      "1.0552114211790404\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0936010980313406>=0.7!\n",
      "1.05875707992083\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.095107629398534>=0.7!\n",
      "1.0499259471418694\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0942829138817742>=0.7!\n",
      "1.0601548313565239\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0942603830257882>=0.7!\n",
      "1.0539831013361367\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0948941739648068>=0.7!\n",
      "1.0569732009423511\n",
      "---\n",
      "Warning, fitted Pareto shape parameter =1.0949016081520524>=0.7!\n",
      "1.0565421406196136\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "opt = ParamStr2(max_iterations=1e5,stepsize_update=\"none\",convergence_algo=\"none\",verbose=true)\n",
    "#opt = Descent(0.5)\n",
    "# CVI Implementation\n",
    "f(x) = x\n",
    "# Priors\n",
    "graph2 = FactorGraph()\n",
    "@RV m ~ GaussianMeanVariance(1.0, 100.0)\n",
    "@RV m_bar ~ Cvi(m,g=f,opt=opt,num_samples=1000,num_iterations=1000)\n",
    "@RV w ~ Gamma(0.01, 0.01)\n",
    "\n",
    "# Observarion model\n",
    "y = Vector{Variable}(undef, n)\n",
    "for i = 1:n\n",
    "    @RV y[i] ~ GaussianMeanPrecision(m_bar, w)\n",
    "    placeholder(y[i], :y, index=i)\n",
    "end\n",
    "\n",
    "# Specify posterior factorization\n",
    "q = PosteriorFactorization(m, w, ids=[:M, :W])\n",
    "# Build the variational update algorithms for each posterior factor\n",
    "algo = messagePassingAlgorithm(free_energy=true)\n",
    "\n",
    "# Generate source code for the algorithms\n",
    "source_code = algorithmSourceCode(algo, free_energy=true)\n",
    "\n",
    "# And inspect the algorithm code\n",
    "#println(source_code)\n",
    "eval(Meta.parse(source_code));\n",
    "\n",
    "\n",
    "data = Dict(:y => y_data)\n",
    "\n",
    "# Initial posterior factors\n",
    "marginals2 = Dict(:m => vague(GaussianMeanVariance),\n",
    "                 :w => vague(Gamma))\n",
    "\n",
    "n_its = 2*n\n",
    "F = Vector{Float64}(undef, n_its) # Initialize vector for storing Free energy\n",
    "m_est = Vector{Float64}(undef, n_its)\n",
    "w_est = Vector{Float64}(undef, n_its)\n",
    "for i = 1:n_its\n",
    "    stepM!(data, marginals2)\n",
    "    stepW!(data, marginals2)\n",
    "    println(mean(marginals2[:m]))\n",
    "    println(\"---\")\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.ḡ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.h̄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+ (generic function with 308 methods)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IJulia 1.5.3",
   "language": "julia",
   "name": "ijulia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
