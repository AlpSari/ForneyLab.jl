{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `C:\\Users\\ALP\\Desktop\\Sioux\\ForneyInternship\\ForneyLab.jl\\Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: This version of CUDA.jl only supports NVIDIA drivers for CUDA 10.1 or higher (yours is for CUDA 9.2.0)\n",
      "└ @ CUDA C:\\Users\\ALP\\.julia\\packages\\CUDA\\mbPFj\\src\\initialization.jl:100\n"
     ]
    }
   ],
   "source": [
    "using ForneyLab\n",
    "using LinearAlgebra,Flux\n",
    "using Random\n",
    "import Distributions: pdf, MvNormal, rand\n",
    "\n",
    "Random.seed!(1) # Set random seed\n",
    "\n",
    "n = 10 # Number of datapoints\n",
    "\n",
    "# Data\n",
    "true_x = [0.5, 0.5] # True value for latent variable x\n",
    "A = diageye(2) # diageye returns an identity matrix of type Diagonal\n",
    "b = zeros(2)\n",
    "Sigma_y = 0.1*[2 1; 1 1] # Observation covariance\n",
    "\n",
    "y_hat_mat = rand(MvNormal(A*true_x + b, Sigma_y), n)' # Data matrix\n",
    "y_hat = [y_hat_mat[i,:] for i=1:n] # Unfold data matrix in a vector of vectors\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ=[0.0729376513458748, 0.20758410336607036]\n",
      "μ=[0.09312788577090446, 0.24251153199866227]\n",
      "μ=[0.09002182989469626, 0.2739013105782836]\n",
      "μ=[0.2941930730540115, 0.2578236409894248]\n",
      "μ=[0.3369883722479696, 0.31702971355520315]\n",
      "μ=[0.3725269017373934, 0.37935040581026525]\n",
      "μ=[0.4042965793129016, 0.38590029349025456]\n",
      "μ=[0.42688276728458996, 0.40244919541759905]\n",
      "μ=[0.4126485176597683, 0.36166762451735524]\n",
      "μ=[0.42355908579791823, 0.3597804219372661]\n"
     ]
    }
   ],
   "source": [
    "f(x)=x\n",
    "num_samples = 1000\n",
    "g = FactorGraph() # Initiate a new factor graph\n",
    "# Model\n",
    "@RV x ~ GaussianMeanVariance(\n",
    "          placeholder(:mu_x, dims=(2,)), \n",
    "          placeholder(:Sigma_x, dims=(2,2))) # Prior with placeholders for statistics\n",
    "\n",
    "@RV x_bar ~ Cvi(x,g=f,opt=Descent(1e-5),num_samples=num_samples,num_iterations=Int64(100000))\n",
    "@RV y ~ GaussianMeanVariance(A*x_bar + b, Sigma_y) # Likelihood\n",
    "\n",
    "placeholder(y, :y, dims=(2,)) # Indicate observed variable; dims indicates the dimensionality of the data\n",
    "algo = messagePassingAlgorithm(x) # Generate algorithm\n",
    "source_code = algorithmSourceCode(algo)\n",
    "eval(Meta.parse(source_code)) # Load algorithm\n",
    "\n",
    "#println(source_code) # Inspect the algorithm\n",
    "# Prior statistics\n",
    "mu_x_0 = zeros(2)\n",
    "Sigma_x_0 = 0.1*diageye(2)\n",
    "\n",
    "# Perform inference\n",
    "mu_x = deepcopy(mu_x_0)\n",
    "Sigma_x = deepcopy(Sigma_x_0)\n",
    "for i = 1:10\n",
    "    data = Dict(:mu_x => mu_x,\n",
    "                :Sigma_x => Sigma_x,\n",
    "                :y => y_hat[i]) # Prepare dictionary with prior statistics and present datapoint\n",
    "    \n",
    "    marginals = step!(data) # Execute the algorithm\n",
    "    \n",
    "    # Today's posterior is tomorrow's prior\n",
    "    mu_x = mean(marginals[:x])\n",
    "    Sigma_x = cov(marginals[:x])\n",
    "    println(\"μ=$(mu_x)\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f(x)=x\n",
    "# num_samples = 1000\n",
    "# g = FactorGraph() # Initiate a new factor graph\n",
    "# # Model\n",
    "# @RV x ~ GaussianMeanVariance(\n",
    "#           placeholder(:mu_x, dims=(2,)), \n",
    "#           placeholder(:Sigma_x, dims=(2,2))) # Prior with placeholders for statistics\n",
    "\n",
    "# @RV x_bar ~ Cvi(x,g=f,opt=Descent(1e-4),num_samples=num_samples,num_iterations=Int64(100000),convergence_optimizer = ConvergenceParamsFE())\n",
    "# @RV y ~ GaussianMeanVariance(A*x_bar + b, Sigma_y) # Likelihood\n",
    "\n",
    "# placeholder(y, :y, dims=(2,)) # Indicate observed variable; dims indicates the dimensionality of the data\n",
    "# algo = messagePassingAlgorithm(x) # Generate algorithm\n",
    "# source_code = algorithmSourceCode(algo)\n",
    "# eval(Meta.parse(source_code)) # Load algorithm\n",
    "\n",
    "# #println(source_code) # Inspect the algorithm\n",
    "# # Prior statistics\n",
    "# mu_x_0 = zeros(2)\n",
    "# Sigma_x_0 = 0.1*diageye(2)\n",
    "\n",
    "# # Perform inference\n",
    "# mu_x = deepcopy(mu_x_0)\n",
    "# Sigma_x = deepcopy(Sigma_x_0)\n",
    "# for i = 1:10\n",
    "#     data = Dict(:mu_x => mu_x,\n",
    "#                 :Sigma_x => Sigma_x,\n",
    "#                 :y => y_hat[i]) # Prepare dictionary with prior statistics and present datapoint\n",
    "    \n",
    "#     marginals = step!(data) # Execute the algorithm\n",
    "    \n",
    "#     # Today's posterior is tomorrow's prior\n",
    "#     mu_x = mean(marginals[:x])\n",
    "#     Sigma_x = cov(marginals[:x])\n",
    "#     println(\"μ=$(mu_x)\")\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.12286397721450719, 0.2645076945955985]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.14377145148828413, 0.29082332629401736]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.13476387189919517, 0.31578904114559103]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.36817593091113593, 0.30720203719277517]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.4122225884434894, 0.36781263700490807]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.44792256708656397, 0.431040733254048]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.4761327438695072, 0.4343437301014103]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.4954062225800522, 0.44836816787447686]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.4719424425503612, 0.40070911091663086]\n",
      "Warning: Stationary Distribution is not achieved.VI result might be inaccurate!\n",
      "μ=[0.47915810333269826, 0.3961710179540145]\n"
     ]
    }
   ],
   "source": [
    "f(x)=x\n",
    "num_samples = 1000\n",
    "g = FactorGraph() # Initiate a new factor graph\n",
    "# Model\n",
    "@RV x ~ GaussianMeanVariance(\n",
    "          placeholder(:mu_x, dims=(2,)), \n",
    "          placeholder(:Sigma_x, dims=(2,2))) # Prior with placeholders for statistics\n",
    "\n",
    "@RV x_bar ~ Cvi(x,g=f,opt=Descent(1e-4),num_samples=num_samples,num_iterations=Int64(100000),convergence_optimizer = ConvergenceParamsMC())\n",
    "@RV y ~ GaussianMeanVariance(A*x_bar + b, Sigma_y) # Likelihood\n",
    "\n",
    "placeholder(y, :y, dims=(2,)) # Indicate observed variable; dims indicates the dimensionality of the data\n",
    "algo = messagePassingAlgorithm(x) # Generate algorithm\n",
    "source_code = algorithmSourceCode(algo)\n",
    "eval(Meta.parse(source_code)) # Load algorithm\n",
    "\n",
    "#println(source_code) # Inspect the algorithm\n",
    "# Prior statistics\n",
    "mu_x_0 = zeros(2)\n",
    "Sigma_x_0 = 0.1*diageye(2)\n",
    "\n",
    "# Perform inference\n",
    "mu_x = deepcopy(mu_x_0)\n",
    "Sigma_x = deepcopy(Sigma_x_0)\n",
    "for i = 1:10\n",
    "    data = Dict(:mu_x => mu_x,\n",
    "                :Sigma_x => Sigma_x,\n",
    "                :y => y_hat[i]) # Prepare dictionary with prior statistics and present datapoint\n",
    "    \n",
    "    marginals = step!(data) # Execute the algorithm\n",
    "    \n",
    "    # Today's posterior is tomorrow's prior\n",
    "    mu_x = mean(marginals[:x])\n",
    "    Sigma_x = cov(marginals[:x])\n",
    "    println(\"μ=$(mu_x)\")\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
